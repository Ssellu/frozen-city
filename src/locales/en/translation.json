{
    "Introduction": "While Visual SLAM technologies perform well in static environments, they often struggle in dynamic settings where moving objects are present. Features extracted from these moving objects can interfere with the accurate calculation of the camera's trajectory, leading to cumulative errors that can compromise the SLAM system. In this project, we aim to mitigate this issue by using deep learning-based Semantic Segmentation to identify and remove dynamic objects. By applying these refined images to Visual SLAM, we seek to achieve a measurable improvement in performance.",
    "Overview": "<p>We have designed and implemented the following workflow:</p><ol class=\"numbered\"><li class=\"text-rise\">Utilize the 'CARLA' simulator, based on Unreal Engine, to obtain images for Semantic Segmentation and V-SLAM. The CARLA simulator allows for the adjustment of various environmental factors, including weather, and provides diverse vehicle models as dynamic objects, making it suitable for this project. We have generated Stereo, RGB-D, and Monocular time-series images from the CARLA simulator for use in Semantic Segmentation and V-SLAM.</li><li class=\"text-rise\">For Semantic Segmentation, we conduct training and performance evaluation using two models: the PaddleSeg model and a custom-built model that we have developed.</li><li class=\"text-rise\">Mask the inferred dynamic objects on the images.</li><li class=\"text-rise\">Extract features from the masked images.</li><li class=\"text-rise\">Apply VSLAM to the extracted features to construct a Map.</li><li class=\"text-rise\">Compare the mapping results in the ORB-SLAM2 V-SLAM framework between the original images and the masked images in both Mono, Stereo, and RGB-D modes.</li><li class=\"text-rise\">Summarize the insights gained and areas for improvement through our experiments. The use of images masked through Semantic Segmentation showed slight improvements when compared to SLAM techniques that do not consider dynamic objects, thereby validating the efficacy of our proposed method.</li></ol>",
    "Simulation": "To acquire images needed for Semantic Segmentation and V-SLAM, we opted for the CARLA simulator. The CARLA simulator provides fine-grained control over environmental conditions such as weather, road objects, and traffic flow. This makes it highly versatile, suitable not only for autonomous driving scenarios but also for meeting the diverse requirements of our project. In this project, we have used CARLA to extract Stereo, RGB-D, and Monocular images. These images serve as training, testing, and inference sets for Semantic Segmentation, as well as Ground Truth Maps for V-SLAM mapping.",
    "AboutCARLA": "<abbr><a href=\"https://carla.org/\" target=\"_blank\">CARLA</a></abbr>(Car Learning to Act) simulator is an open-source platform that provides a realistic environment for the development, training, and validation of autonomous driving systems. With high-fidelity graphics and physics, CARLA aims to provide a near-to-real-world scenario, making it easier to ensure the safety and performance of autonomous vehicles before they are deployed in real life. It supports various weather conditions, different types of roads, and includes a variety of sensors to assist in data collection. Moreover, CARLA is compatible with ROS (Robot Operating System) and can be integrated with machine learning libraries, offering a comprehensive ecosystem for researchers and developers in the field of autonomous driving.",
    "Segmentation": "We have conducted training and inference using both a state-of-the-art model as listed in the <a href=\"https://paperswithcode.com/sota/real-time-semantic-segmentation-on-cityscapes\" target=\"_blank\">SOTA</a> and our custom model. We selected the model based on the following criteria:",
    "Conclusion": "<p>Our project utilized the CARLA simulator to generate an outdoor driving dataset and performed Semantic Segmentation on dynamic objects. The ultimate goal was to enhance the accuracy of Visual SLAM.<br>When compared with other SLAM technologies that consider dynamic objects, such as DynaSLAM, our approach showed similar results, thereby validating its effectiveness. However, we identified several limitations and areas for improvement, gaining valuable insights in the process.</p><p>A significant limitation was that our model was undertrained, leading to Underfitting. Specifically, the model was not sufficiently trained on various vehicles, plants, and weather conditions present in the CARLA simulator. As a result, our custom CARLA dataset showed a lower mIoU score.</p><p>In the case of objects significantly affected by wind, such as roadside trees and flags, they could be classified as static objects in the CARLA environment due to the low wind intensity. A particular reason for classifying them as static was that simple masking methods made the masked edges act as new features, rendering the masking process ineffective. If we plan to apply our project to the real world, this issue must be resolved. Upon exploring solutions, we concluded that more advanced masking techniques, such as inpaint methods, and additional information like Instance Segmentation are needed.</p><p>Although hardware limitations prevented us from conducting real-time tests, we believe that utilizing the ROS-bridge package for real-time testing in a ROS environment would be an effective strategy for future validation and improvement.</p>"
}